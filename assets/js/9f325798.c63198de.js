"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[8681],{3905:(e,t,n)=>{n.d(t,{Zo:()=>l,kt:()=>f});var a=n(7294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var c=a.createContext({}),h=function(e){var t=a.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},l=function(e){var t=h(e.components);return a.createElement(c.Provider,{value:t},e.children)},u="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,r=e.originalType,c=e.parentName,l=o(e,["components","mdxType","originalType","parentName"]),u=h(n),d=i,f=u["".concat(c,".").concat(d)]||u[d]||p[d]||r;return n?a.createElement(f,s(s({ref:t},l),{},{components:n})):a.createElement(f,s({ref:t},l))}));function f(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=n.length,s=new Array(r);s[0]=d;var o={};for(var c in t)hasOwnProperty.call(t,c)&&(o[c]=t[c]);o.originalType=e,o[u]="string"==typeof e?e:i,s[1]=o;for(var h=2;h<r;h++)s[h]=n[h];return a.createElement.apply(null,s)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},2735:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>p,frontMatter:()=>r,metadata:()=>o,toc:()=>h});var a=n(7462),i=(n(7294),n(3905));const r={},s="What are LLM chains and why are they useful?",o={unversionedId:"chains/what-are-chains",id:"chains/what-are-chains",title:"What are LLM chains and why are they useful?",description:'Chains are a concept in the world of language models designed to model common patterns for applying large language models (LLMs) to a sequence of tasks. Although the term "chain" might suggest that it strictly involves chaining together LLM steps, the name has stuck, and it is now used more broadly.',source:"@site/docs/chains/00-what-are-chains.md",sourceDirName:"chains",slug:"/chains/what-are-chains",permalink:"/docs/chains/what-are-chains",draft:!1,editUrl:"https://github.com/sobelio/llm-chain/tree/main/docs/docs/chains/00-what-are-chains.md",tags:[],version:"current",sidebarPosition:0,frontMatter:{},sidebar:"sidebar",previous:{title:"Development Setup",permalink:"/docs/dev-setup"},next:{title:"sequential-chains",permalink:"/docs/chains/sequential-chains"}},c={},h=[{value:"Sequential Chains",id:"sequential-chains",level:2},{value:"MapReduce Chains",id:"mapreduce-chains",level:2},{value:"Conversation Chains",id:"conversation-chains",level:2}],l={toc:h},u="wrapper";function p(e){let{components:t,...n}=e;return(0,i.kt)(u,(0,a.Z)({},l,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"what-are-llm-chains-and-why-are-they-useful"},"What are LLM chains and why are they useful?"),(0,i.kt)("p",null,'Chains are a concept in the world of language models designed to model common patterns for applying large language models (LLMs) to a sequence of tasks. Although the term "chain" might suggest that it strictly involves chaining together LLM steps, the name has stuck, and it is now used more broadly.'),(0,i.kt)("p",null,"Chains provide a convenient abstraction for organizing and executing a series of LLM steps in various ways to achieve desired outcomes. In this document, we will explore three main types of chains: Sequential, MapReduce, and Conversation chains. Each chain has its unique characteristics and serves specific purposes in applying LLMs."),(0,i.kt)("h2",{id:"sequential-chains"},"Sequential Chains"),(0,i.kt)("p",null,"Sequential chains are a simple yet powerful approach to applying LLMs. They connect multiple steps together in a sequence, where the output of the first step becomes the input of the second step, and so on. This method allows for straightforward processing of information, where each step builds upon the results of the previous one."),(0,i.kt)("h2",{id:"mapreduce-chains"},"MapReduce Chains"),(0,i.kt)("p",null,"MapReduce chains are designed to work with one or more documents. They split the documents into chunks that fit the LLM's context window and then apply the Map prompt to each chunk. After processing the chunks, a Reduce prompt is used to combine the results into a final output."),(0,i.kt)("p",null,"This approach is particularly useful when working with large documents or multiple documents, as it enables parallel processing and efficient combination of results."),(0,i.kt)("h2",{id:"conversation-chains"},"Conversation Chains"),(0,i.kt)("p",null,"Conversation chains are tailored for chat-style use cases, where maintaining a conversation history with the LLM is essential. This chain type keeps building up a history of chat messages, removing the ones that do not fit the context window, starting from the oldest to the newest. The conversation chain allows for more dynamic and interactive experiences when working with LLMs."),(0,i.kt)("p",null,"In summary, chains are a useful concept in applying LLMs, as they provide a structured way of organizing and executing LLM steps for various tasks. Each chain type has its unique characteristics and advantages, and choosing the right chain for your specific use case can significantly improve the effectiveness of your LLM application."))}p.isMDXComponent=!0}}]);